# ğŸ¯ InterviewIQ - AI-Powered Interview Practice Platform

> An intelligent interview preparation system that conducts realistic mock interviews with voice interaction, resume analysis, and personalized questioning using AI.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.1.2-green.svg)](https://flask.palletsprojects.com/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3.18-orange.svg)](https://www.langchain.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Demo](#-demo)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [API Endpoints](#-api-endpoints)
- [How It Works](#-how-it-works)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

---

## âœ¨ Features

### ğŸ¤ Voice Interaction
- **Browser-based audio recording** using Web Audio API
- **Real-time transcription** with Google Speech Recognition
- **No external dependencies** - WAV encoding directly in browser
- **Transcription-to-text field** - Review and edit before sending

### ğŸ¤– AI-Powered Interviews
- **Natural conversation flow** - Acts like a real interviewer
- **Context-aware questioning** - Remembers conversation history
- **Adaptive responses** - Adjusts difficulty based on answers
- **HuggingFace LLM integration** - Uses `openai/gpt-oss-120b` model

### ğŸ“„ Resume Analysis (RAG)
- **PDF upload and processing** - Extracts text from resume
- **Vector embeddings** - Uses Sentence Transformers
- **Semantic search** - Finds relevant resume sections
- **Astra DB storage** - Cloud-native vector database
- **Personalized questions** - Based on your experience

### ğŸ¨ Modern UI/UX
- **Dark/Light theme toggle** - Persistent across sessions
- **Message alignment** - You (right) / AI (left)
- **Responsive design** - Works on desktop and mobile
- **Auto-scroll chat** - Smooth message flow
- **Clean animations** - Professional look and feel

### ğŸ”’ Secure & Private
- **No local file storage** - Everything in-memory or cloud
- **Session-based isolation** - Each user gets own context
- **API key via UI** - No hardcoded credentials
- **Auto-cleanup on restart** - Fresh start every time

---

## ğŸ¬ Demo

### Screenshot
![InterviewIQ Interface](https://via.placeholder.com/800x500?text=InterviewIQ+Interface)

### Quick Start
```bash
# Clone the repository
git clone https://github.com/yourusername/interviewiq.git
cd interviewiq

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your credentials

# Run the application
python main.py
```

Visit `http://127.0.0.1:5000` and start practicing!

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Microphone  â”‚â†’ â”‚ Web Audio APIâ”‚â†’ â”‚  WAV Encoder    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚  chat.js     â”‚                          â”‚
â”‚                    â”‚  (Frontend)  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/JSON
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Flask Server                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    main.py                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ /speech â”‚  â”‚ /chat   â”‚  â”‚ /uploadâ”‚  â”‚ /set_apiâ”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚            â”‚           â”‚            â”‚            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚transcribe â”‚ â”‚ AI_model   â”‚ â”‚      â”‚  Session   â”‚     â”‚
â”‚    â”‚    .py    â”‚ â”‚   .py      â”‚ â”‚      â”‚  Storage   â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚           â”‚           â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚           â”‚           â”‚
           â†“           â†“           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Google  â”‚  â”‚  HuggingFace API   â”‚  â”‚  Astra DB    â”‚
    â”‚  Speech  â”‚  â”‚  (LLM Inference)   â”‚  â”‚  (Vectors)   â”‚
    â”‚   API    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Flask 3.1.2** - Web framework
- **LangChain 0.3.18** - LLM orchestration
- **HuggingFace Hub** - Model inference
- **Cassio** - Astra DB integration
- **SpeechRecognition** - Audio transcription
- **PyPDF** - Resume parsing
- **Sentence Transformers** - Embeddings

### Frontend
- **Vanilla JavaScript** - No framework overhead
- **Web Audio API** - Browser audio capture
- **CSS Grid/Flexbox** - Responsive layout
- **LocalStorage** - Theme persistence

### Database & AI
- **Astra DB** - Vector storage (Cassandra)
- **HuggingFace LLM** - `openai/gpt-oss-120b`
- **Sentence Transformers** - `all-MiniLM-L6-v2`
- **Google Speech Recognition** - Free tier

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Modern web browser (Chrome/Edge recommended)
- Active internet connection

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/interviewiq.git
cd interviewiq
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Set Up Environment Variables
Create a `.env` file in the project root:

```bash
# .env
ASTRA_DB_APPLICATION_TOKEN=AstraCS:xxxxx...
ASTRA_DB_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

# Note: HuggingFace token is set via UI, not here
```

---

## âš™ï¸ Configuration

### 1. Get Astra DB Credentials

1. Go to [Astra DB](https://astra.datastax.com/)
2. Create a free account
3. Create a new database
4. Generate an application token
5. Copy token and database ID to `.env`

### 2. Get HuggingFace API Key

1. Go to [HuggingFace](https://huggingface.co/)
2. Sign up/login
3. Go to Settings â†’ Access Tokens
4. Create a new token (read permission)
5. **Paste it in the web UI** (not in `.env`)

### 3. Configure Settings (Optional)

Edit `AI_model.py` to customize:
```python
# LLM Model
repo_id="openai/gpt-oss-120b"  # Change model

# Max response length
max_new_tokens=512

# Embedding model
model_name="sentence-transformers/all-MiniLM-L6-v2"

# RAG settings
chunk_size=1000
chunk_overlap=200
search_kwargs={"k": 3}
```

---

## ğŸš€ Usage

### Starting the Server

**Option 1: Python**
```bash
python main.py
```

**Option 2: PowerShell Script (Windows)**
```powershell
.\start_app.ps1
```

Server will start at `http://127.0.0.1:5000`

### Using the Interface

#### 1. Set API Key
- Open the app in your browser
- Left sidebar â†’ Paste HuggingFace token
- Click "ğŸ’¾ Save API Key"
- You'll see a success message

#### 2. Choose Interview Mode
- **General Interview**: Standard questions without resume
- **Resume-Based**: Personalized questions from your background

#### 3. Upload Resume (Optional)
- Click "ğŸ“ Choose PDF File"
- Select your resume PDF
- Wait for "Resume uploaded & processed" message

#### 4. Start Interview

**Voice Input:**
1. Click microphone button ğŸ¤
2. Speak your answer
3. Click again to stop â¹ï¸
4. Transcribed text appears in input field
5. Edit if needed
6. Press Enter to send

**Text Input:**
- Type your message in the text area
- Press Enter or click Send button

#### 5. Manage Chat
- **Clear Chat**: Click ğŸ—‘ï¸ to reset conversation
- **Toggle Theme**: Click ğŸŒ™/â˜€ï¸ for dark/light mode
- **New Chat**: Click "âœ¨ New Chat" to start fresh

---

## ğŸ“ Project Structure

```
interviewiq/
â”œâ”€â”€ main.py                    # Flask application & endpoints
â”œâ”€â”€ AI_model.py               # LLM chat logic with RAG
â”œâ”€â”€ transcribe.py             # Audio-to-text conversion
â”œâ”€â”€ speech_creator.py         # CLI voice capture (optional)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env                      # Environment variables
â”œâ”€â”€ start_app.ps1            # Windows startup script
â”œâ”€â”€ README.md                # This file
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ chat.css             # UI styling & themes
â”‚   â””â”€â”€ chat.js              # Frontend logic & WAV recorder
â”‚
â””â”€â”€ templates/
    â””â”€â”€ chat.html            # Main interface HTML
```

### Key Files Explained

**`main.py`**
- Flask server initialization
- API endpoints (`/chat`, `/speech`, `/upload_resume`, etc.)
- Session management
- Auto-cleanup on startup

**`AI_model.py`**
- LangChain conversation chain
- HuggingFace LLM integration
- Resume RAG setup (PDF â†’ Embeddings â†’ Astra DB)
- Chat history management

**`transcribe.py`**
- Converts WAV audio buffer to text
- Uses Google Speech Recognition API
- Handles errors gracefully

**`chat.js`**
- Web Audio API setup
- PCM WAV encoding (16-bit mono)
- AJAX requests to backend
- Theme toggle & UI updates

**`chat.css`**
- Dark/light theme variables
- Responsive grid layout
- Message bubbles & animations

---

## ğŸ”Œ API Endpoints

### `POST /set_api`
Save HuggingFace API key to session.

**Request:**
```json
{
  "api_key": "hf_xxxxx..."
}
```

**Response:**
```json
{
  "status": "success",
  "message": "API key saved successfully"
}
```

---

### `POST /speech`
Transcribe audio to text (transcription only, no AI response).

**Request:** `multipart/form-data`
- `audio`: WAV file blob
- `session_id`: Session identifier

**Response:**
```json
{
  "result": "Transcribed text from audio"
}
```

---

### `POST /chat`
Send text message and get AI response.

**Request:**
```json
{
  "message": "Tell me about yourself",
  "session_id": "default",
  "use_resume": false
}
```

**Response:**
```json
{
  "response": "Hello! I'm your interview coach..."
}
```

---

### `POST /upload_resume`
Upload and process PDF resume.

**Request:** `multipart/form-data`
- `resume`: PDF file
- `session_id`: Session identifier

**Response:**
```json
{
  "status": "success",
  "message": "Resume uploaded successfully",
  "filename": "resume.pdf"
}
```

---

### `POST /clear_chat`
Clear conversation history for a session.

**Request:**
```json
{
  "session_id": "default"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Chat history cleared"
}
```

---

## ğŸ§  How It Works

### 1. Audio Recording Flow
```
User clicks mic â†’ Browser requests permission
                â†’ Web Audio API starts capture
                â†’ ScriptProcessor collects PCM samples
                â†’ Float32Array accumulates audio data
User clicks stop â†’ Samples merged into single buffer
                â†’ Encoded as 16-bit PCM WAV
                â†’ Sent to /speech endpoint
                â†’ Google Speech Recognition transcribes
                â†’ Text appears in input field
                â†’ User reviews/edits
                â†’ Manually sends to AI
```

### 2. Chat Flow
```
User message â†’ Flask /chat endpoint
            â†’ AI_model.chat_with_history()
            â†’ Retrieves session history
            â†’ (Optional) Fetches resume context from Astra DB
            â†’ Constructs prompt with history + context
            â†’ Calls HuggingFace LLM API
            â†’ AI response returned
            â†’ Added to session history
            â†’ Displayed in UI
```

### 3. Resume RAG Flow
```
PDF upload â†’ PyPDF extracts text
          â†’ RecursiveCharacterTextSplitter chunks text
          â†’ SentenceTransformer creates embeddings
          â†’ Embeddings stored in Astra DB (Cassandra)
          â†’ On query: Semantic search finds top-k chunks
          â†’ Chunks appended to user message as context
          â†’ LLM uses context for personalized questions
```

### 4. Auto-Cleanup (Startup)
```
Server starts â†’ cleanup_all_resume_tables()
             â†’ Connects to Astra DB
             â†’ Queries system schema for tables
             â†’ Filters tables starting with 'resume_'
             â†’ Drops each table with DROP TABLE IF EXISTS
             â†’ Reports count of dropped tables
             â†’ Server continues normally
```

---

## ğŸ› Troubleshooting

### Issue: "Please provide your HuggingFace API key"
**Solution:** 
1. Get token from https://huggingface.co/settings/tokens
2. Paste in sidebar and click "Save API Key"
3. Refresh page if needed

---

### Issue: "Microphone error: NotAllowedError"
**Solution:**
1. Browser blocked microphone access
2. Click lock icon in address bar
3. Allow microphone permission
4. Refresh page

---

### Issue: "Could not process audio"
**Solution:**
1. Check microphone is working (test in other apps)
2. Speak louder/closer to mic
3. Try different browser (Chrome/Edge recommended)
4. Check internet connection (Google Speech API requires online)

---

### Issue: "Astra DB credentials not found"
**Solution:**
1. Verify `.env` file exists in project root
2. Check `ASTRA_DB_APPLICATION_TOKEN` and `ASTRA_DB_ID` are set
3. Ensure no extra spaces or quotes around values
4. Restart server after editing `.env`

---

### Issue: Import errors on startup
**Solution:**
```bash
# Ensure virtual environment is activated
# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

---

### Issue: Port 5000 already in use
**Solution:**
```bash
# Change port in main.py:
app.run(debug=True, host='127.0.0.1', port=5001)
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

### 1. Fork & Clone
```bash
git clone https://github.com/yourusername/interviewiq.git
cd interviewiq
git checkout -b feature/your-feature-name
```

### 2. Make Changes
- Follow existing code style
- Add comments for complex logic
- Test thoroughly before committing

### 3. Commit & Push
```bash
git add .
git commit -m "feat: add your feature description"
git push origin feature/your-feature-name
```

### 4. Create Pull Request
- Go to GitHub repository
- Click "New Pull Request"
- Describe changes and why they're needed
- Wait for review

### Development Guidelines
- **Code Style**: Follow PEP 8 for Python
- **Commits**: Use conventional commits (`feat:`, `fix:`, `docs:`)
- **Testing**: Test all endpoints before submitting
- **Documentation**: Update README if adding features

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 InterviewIQ

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ™ Acknowledgments

### Technologies
- [LangChain](https://www.langchain.com/) - LLM framework
- [HuggingFace](https://huggingface.co/) - Model hosting
- [Astra DB](https://astra.datastax.com/) - Vector database
- [Flask](https://flask.palletsprojects.com/) - Web framework
- [Sentence Transformers](https://www.sbert.net/) - Embeddings

### Inspiration
- Real interview experiences
- AI tutoring systems
- Voice assistants

### Contributors
- **Gaurav** - Initial development
- **GitHub Copilot** - Code assistance

---

## ğŸ“ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/interviewiq/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/interviewiq/discussions)
- **Email**: your.email@example.com

---

## ğŸ—ºï¸ Roadmap

### v1.1 (Planned)
- [ ] Multiple LLM model support
- [ ] Interview performance analytics
- [ ] Export interview transcripts
- [ ] Mobile app (React Native)

### v2.0 (Future)
- [ ] Multi-user support with authentication
- [ ] Custom interview templates
- [ ] Video interview simulation
- [ ] AI feedback on answers

---

## ğŸ“Š Stats

![GitHub Stars](https://img.shields.io/github/stars/yourusername/interviewiq?style=social)
![GitHub Forks](https://img.shields.io/github/forks/yourusername/interviewiq?style=social)
![GitHub Issues](https://img.shields.io/github/issues/yourusername/interviewiq)
![GitHub Pull Requests](https://img.shields.io/github/issues-pr/yourusername/interviewiq)

---

<div align="center">

**Made with â¤ï¸ by developers, for developers**

â­ Star this repo if you find it helpful!

[Report Bug](https://github.com/yourusername/interviewiq/issues) Â· [Request Feature](https://github.com/yourusername/interviewiq/issues) Â· [Documentation](https://github.com/yourusername/interviewiq/wiki)

</div>
